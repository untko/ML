{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac09b930",
   "metadata": {},
   "source": [
    "ref : https://d3rlpy.readthedocs.io/en/stable/tutorials/finetuning.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f890c53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
      "/opt/anaconda3/envs/python313/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:10.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSignatures have been automatically determined.\u001b[0m \u001b[36maction_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('int32')], shape=[(1,)])\u001b[0m \u001b[36mobservation_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(4,)])\u001b[0m \u001b[36mreward_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(1,)])\u001b[0m\n",
      "\u001b[2m2025-09-15 23:10.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction-space has been automatically determined.\u001b[0m \u001b[36maction_space\u001b[0m=\u001b[35m<ActionSpace.DISCRETE: 2>\u001b[0m\n",
      "\u001b[2m2025-09-15 23:10.43\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction size has been automatically determined.\u001b[0m \u001b[36maction_size\u001b[0m=\u001b[35m2\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# setup\n",
    "import d3rlpy\n",
    "import gymnasium as gym\n",
    "# setup random CartPole-v0 dataset and environment\n",
    "dataset, env = d3rlpy.datasets.get_dataset(\"cartpole-random\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e52e2fa",
   "metadata": {},
   "source": [
    "## pretrain with data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cf7a7ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:11.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mdataset info                  \u001b[0m \u001b[36mdataset_info\u001b[0m=\u001b[35mDatasetInfo(observation_signature=Signature(dtype=[dtype('float32')], shape=[(4,)]), action_signature=Signature(dtype=[dtype('int32')], shape=[(1,)]), reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)]), action_space=<ActionSpace.DISCRETE: 2>, action_size=2)\u001b[0m\n",
      "\u001b[2m2025-09-15 23:11.21\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mBuilding models...            \u001b[0m\n",
      "\u001b[2m2025-09-15 23:11.21\u001b[0m [\u001b[32m\u001b[1mdebug    \u001b[0m] \u001b[1mModels have been built.       \u001b[0m\n",
      "\u001b[2m2025-09-15 23:11.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/DQN_20250915231121\u001b[0m\n",
      "\u001b[2m2025-09-15 23:11.21\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [4], 'action_size': 2, 'config': {'type': 'dqn', 'params': {'batch_size': 32, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 6.25e-05, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 8000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100%|██████████| 10000/10000 [00:10<00:00, 970.27it/s, loss=0.00736]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:11.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_20250915231121: epoch=1 step=10000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00018841843605041505, 'time_algorithm_update': 0.0007871738672256469, 'loss': 0.007365216030893373, 'time_step': 0.0010250765323638917}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m10000\u001b[0m\n",
      "\u001b[2m2025-09-15 23:11.32\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_20250915231121/model_10000.d3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/10: 100%|██████████| 10000/10000 [00:10<00:00, 937.04it/s, loss=0.0182]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:11.42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_20250915231121: epoch=2 step=20000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00019923093318939208, 'time_algorithm_update': 0.0008019806861877441, 'loss': 0.018201471415307605, 'time_step': 0.0010569590330123902}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m20000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:11.42\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_20250915231121/model_20000.d3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/10: 100%|██████████| 10000/10000 [00:10<00:00, 930.45it/s, loss=0.0273]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:11.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_20250915231121: epoch=3 step=30000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00020180704593658448, 'time_algorithm_update': 0.0008137751340866089, 'loss': 0.027274789915600558, 'time_step': 0.0010684561014175414}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m30000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:11.53\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_20250915231121/model_30000.d3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/10: 100%|██████████| 10000/10000 [00:09<00:00, 1038.09it/s, loss=0.0322]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:12.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_20250915231121: epoch=4 step=40000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00017958033084869386, 'time_algorithm_update': 0.0007311445713043213, 'loss': 0.032225199119444006, 'time_step': 0.0009583213567733765}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m40000\u001b[0m\n",
      "\u001b[2m2025-09-15 23:12.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_20250915231121/model_40000.d3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5/10: 100%|██████████| 10000/10000 [00:10<00:00, 964.46it/s, loss=0.0399]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:12.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_20250915231121: epoch=5 step=50000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m5\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0001948422908782959, 'time_algorithm_update': 0.0007835359811782837, 'loss': 0.03992075965790427, 'time_step': 0.0010313687324523925}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m50000\u001b[0m\n",
      "\u001b[2m2025-09-15 23:12.13\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_20250915231121/model_50000.d3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6/10: 100%|██████████| 10000/10000 [00:13<00:00, 721.13it/s, loss=0.0472]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:12.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_20250915231121: epoch=6 step=60000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m6\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00029952788352966307, 'time_algorithm_update': 0.0010129031896591186, 'loss': 0.04719287119450746, 'time_step': 0.001379119634628296}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m60000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:12.27\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_20250915231121/model_60000.d3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|██████████| 10000/10000 [00:10<00:00, 971.66it/s, loss=0.0564]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:12.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_20250915231121: epoch=7 step=70000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m7\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00019867105484008788, 'time_algorithm_update': 0.0007727617025375367, 'loss': 0.05639871674312744, 'time_step': 0.0010233393430709838}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m70000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:12.37\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_20250915231121/model_70000.d3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/10: 100%|██████████| 10000/10000 [00:09<00:00, 1064.69it/s, loss=0.065]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:12.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_20250915231121: epoch=8 step=80000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m8\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.00018249795436859131, 'time_algorithm_update': 0.0007041855335235596, 'loss': 0.06508912614049622, 'time_step': 0.0009335471630096435}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m80000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:12.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_20250915231121/model_80000.d3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/10: 100%|██████████| 10000/10000 [00:09<00:00, 1032.54it/s, loss=0.0721]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:12.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_20250915231121: epoch=9 step=90000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m9\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0001856348991394043, 'time_algorithm_update': 0.0007281837463378907, 'loss': 0.07202687859864673, 'time_step': 0.0009635720014572143}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m90000\u001b[0m\n",
      "\u001b[2m2025-09-15 23:12.56\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_20250915231121/model_90000.d3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10/10: 100%|██████████| 10000/10000 [00:10<00:00, 970.36it/s, loss=0.078] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:13.07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_20250915231121: epoch=10 step=100000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m10\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_sample_batch': 0.0001993642807006836, 'time_algorithm_update': 0.0007728094577789307, 'loss': 0.07800422673694557, 'time_step': 0.0010251665353775024}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m100000\u001b[0m\n",
      "\u001b[2m2025-09-15 23:13.07\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_20250915231121/model_100000.d3\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1,\n",
       "  {'time_sample_batch': 0.00018841843605041505,\n",
       "   'time_algorithm_update': 0.0007871738672256469,\n",
       "   'loss': 0.007365216030893373,\n",
       "   'time_step': 0.0010250765323638917}),\n",
       " (2,\n",
       "  {'time_sample_batch': 0.00019923093318939208,\n",
       "   'time_algorithm_update': 0.0008019806861877441,\n",
       "   'loss': 0.018201471415307605,\n",
       "   'time_step': 0.0010569590330123902}),\n",
       " (3,\n",
       "  {'time_sample_batch': 0.00020180704593658448,\n",
       "   'time_algorithm_update': 0.0008137751340866089,\n",
       "   'loss': 0.027274789915600558,\n",
       "   'time_step': 0.0010684561014175414}),\n",
       " (4,\n",
       "  {'time_sample_batch': 0.00017958033084869386,\n",
       "   'time_algorithm_update': 0.0007311445713043213,\n",
       "   'loss': 0.032225199119444006,\n",
       "   'time_step': 0.0009583213567733765}),\n",
       " (5,\n",
       "  {'time_sample_batch': 0.0001948422908782959,\n",
       "   'time_algorithm_update': 0.0007835359811782837,\n",
       "   'loss': 0.03992075965790427,\n",
       "   'time_step': 0.0010313687324523925}),\n",
       " (6,\n",
       "  {'time_sample_batch': 0.00029952788352966307,\n",
       "   'time_algorithm_update': 0.0010129031896591186,\n",
       "   'loss': 0.04719287119450746,\n",
       "   'time_step': 0.001379119634628296}),\n",
       " (7,\n",
       "  {'time_sample_batch': 0.00019867105484008788,\n",
       "   'time_algorithm_update': 0.0007727617025375367,\n",
       "   'loss': 0.05639871674312744,\n",
       "   'time_step': 0.0010233393430709838}),\n",
       " (8,\n",
       "  {'time_sample_batch': 0.00018249795436859131,\n",
       "   'time_algorithm_update': 0.0007041855335235596,\n",
       "   'loss': 0.06508912614049622,\n",
       "   'time_step': 0.0009335471630096435}),\n",
       " (9,\n",
       "  {'time_sample_batch': 0.0001856348991394043,\n",
       "   'time_algorithm_update': 0.0007281837463378907,\n",
       "   'loss': 0.07202687859864673,\n",
       "   'time_step': 0.0009635720014572143}),\n",
       " (10,\n",
       "  {'time_sample_batch': 0.0001993642807006836,\n",
       "   'time_algorithm_update': 0.0007728094577789307,\n",
       "   'loss': 0.07800422673694557,\n",
       "   'time_step': 0.0010251665353775024})]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setup algorithm\n",
    "dqn = d3rlpy.algos.DQNConfig().create()\n",
    "\n",
    "# start offline training\n",
    "dqn.fit(dataset, n_steps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9da212f",
   "metadata": {},
   "source": [
    "## finetune with environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8b256a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:13.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mSignatures have been automatically determined.\u001b[0m \u001b[36maction_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('int64')], shape=[()])\u001b[0m \u001b[36mobservation_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[(4,)])\u001b[0m \u001b[36mreward_signature\u001b[0m=\u001b[35mSignature(dtype=[dtype('float32')], shape=[[1]])\u001b[0m\n",
      "\u001b[2m2025-09-15 23:13.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction-space has been automatically determined.\u001b[0m \u001b[36maction_space\u001b[0m=\u001b[35m<ActionSpace.DISCRETE: 2>\u001b[0m\n",
      "\u001b[2m2025-09-15 23:13.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mAction size has been automatically determined.\u001b[0m \u001b[36maction_size\u001b[0m=\u001b[35m2\u001b[0m\n",
      "\u001b[2m2025-09-15 23:13.26\u001b[0m [\u001b[33m\u001b[1mwarning  \u001b[0m] \u001b[1mSkip building models since they're already built.\u001b[0m\n",
      "\u001b[2m2025-09-15 23:13.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDirectory is created at d3rlpy_logs/DQN_online_20250915231326\u001b[0m\n",
      "\u001b[2m2025-09-15 23:13.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mParameters                    \u001b[0m \u001b[36mparams\u001b[0m=\u001b[35m{'observation_shape': [4], 'action_size': 2, 'config': {'type': 'dqn', 'params': {'batch_size': 32, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'compile_graph': False, 'learning_rate': 6.25e-05, 'optim_factory': {'type': 'adam', 'params': {'clip_grad_norm': None, 'lr_scheduler_factory': {'type': 'none', 'params': {}}, 'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 8000}}}\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 9964/100000 [00:09<01:40, 898.49it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:13.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_online_20250915231326/model_10000.d3\u001b[0m\n",
      "\u001b[2m2025-09-15 23:13.35\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_online_20250915231326: epoch=1 step=10000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m1\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_inference': 7.703371047973633e-05, 'time_environment_step': 7.562923431396484e-06, 'time_step': 0.0009134414434432983, 'time_sample_batch': 0.00017064144203030645, 'time_algorithm_update': 0.0006517341577792653, 'loss': 0.11324180778098888, 'rollout_return': 124.15}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m10000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 19903/100000 [00:18<01:13, 1094.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:13.44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_online_20250915231326/model_20000.d3\u001b[0m\n",
      "\u001b[2m2025-09-15 23:13.44\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_online_20250915231326: epoch=2 step=20000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m2\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_inference': 7.533414363861085e-05, 'time_environment_step': 7.288765907287598e-06, 'time_sample_batch': 0.00017793288230895997, 'time_algorithm_update': 0.0006440235853195191, 'loss': 0.11414843951832736, 'time_step': 0.0009137812614440918, 'rollout_return': 143.77142857142857}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m20000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 29987/100000 [00:27<01:06, 1059.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:13.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_online_20250915231326/model_30000.d3\u001b[0m\n",
      "\u001b[2m2025-09-15 23:13.54\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_online_20250915231326: epoch=3 step=30000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m3\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_inference': 7.441093921661377e-05, 'time_environment_step': 6.870627403259277e-06, 'time_sample_batch': 0.00018121778964996337, 'time_algorithm_update': 0.000647471809387207, 'loss': 0.11324450684871408, 'time_step': 0.0009191047668457032, 'rollout_return': 154.0}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m30000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 39923/100000 [00:37<00:53, 1115.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:14.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_online_20250915231326/model_40000.d3\u001b[0m\n",
      "\u001b[2m2025-09-15 23:14.03\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_online_20250915231326: epoch=4 step=40000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m4\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_inference': 8.135955333709716e-05, 'time_environment_step': 7.450366020202636e-06, 'time_sample_batch': 0.00019643042087554932, 'time_algorithm_update': 0.0006839004039764404, 'loss': 0.1119140153462242, 'time_step': 0.000979066514968872, 'rollout_return': 152.77272727272728}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m40000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 49967/100000 [00:49<01:14, 668.39it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:14.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_online_20250915231326/model_50000.d3\u001b[0m\n",
      "\u001b[2m2025-09-15 23:14.15\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_online_20250915231326: epoch=5 step=50000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m5\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_inference': 0.00010088553428649903, 'time_environment_step': 8.76593589782715e-06, 'time_sample_batch': 0.00025231287479400636, 'time_algorithm_update': 0.0007761244058609009, 'loss': 0.11648410189293791, 'time_step': 0.0011526607275009154, 'rollout_return': 155.78125}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m50000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 59901/100000 [00:59<00:37, 1064.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:14.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_online_20250915231326/model_60000.d3\u001b[0m\n",
      "\u001b[2m2025-09-15 23:14.26\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_online_20250915231326: epoch=6 step=60000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m6\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_inference': 8.643903732299805e-05, 'time_environment_step': 8.384203910827637e-06, 'time_sample_batch': 0.00023087091445922852, 'time_algorithm_update': 0.0007238237857818603, 'loss': 0.11818782082206453, 'time_step': 0.0010605913639068604, 'rollout_return': 178.91071428571428}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m60000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 69912/100000 [01:10<00:26, 1118.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:14.36\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_online_20250915231326/model_70000.d3\u001b[0m\n",
      "\u001b[2m2025-09-15 23:14.36\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_online_20250915231326: epoch=7 step=70000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m7\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_inference': 8.605172634124756e-05, 'time_environment_step': 9.69548225402832e-06, 'time_sample_batch': 0.00023554022312164305, 'time_algorithm_update': 0.0007304699182510376, 'loss': 0.12105225314275594, 'time_step': 0.0010727733850479126, 'rollout_return': 187.9433962264151}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m70000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 79916/100000 [01:21<00:22, 895.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:14.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_online_20250915231326/model_80000.d3\u001b[0m\n",
      "\u001b[2m2025-09-15 23:14.47\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_online_20250915231326: epoch=8 step=80000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m8\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_inference': 8.950548171997071e-05, 'time_environment_step': 8.527040481567383e-06, 'time_sample_batch': 0.0002479844570159912, 'time_algorithm_update': 0.0007276175737380981, 'loss': 0.12327731345740031, 'time_step': 0.001084607172012329, 'rollout_return': 179.73214285714286}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m80000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 89917/100000 [01:32<00:09, 1114.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:14.58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_online_20250915231326/model_90000.d3\u001b[0m\n",
      "\u001b[2m2025-09-15 23:14.58\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_online_20250915231326: epoch=9 step=90000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m9\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_inference': 8.570070266723632e-05, 'time_environment_step': 7.910394668579102e-06, 'time_sample_batch': 0.00025331413745880127, 'time_algorithm_update': 0.0007107664823532105, 'loss': 0.12430196502272738, 'time_step': 0.0010684901237487793, 'rollout_return': 171.63793103448276}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m90000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 99925/100000 [01:42<00:00, 1105.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m2025-09-15 23:15.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mModel parameters are saved to d3rlpy_logs/DQN_online_20250915231326/model_100000.d3\u001b[0m\n",
      "\u001b[2m2025-09-15 23:15.08\u001b[0m [\u001b[32m\u001b[1minfo     \u001b[0m] \u001b[1mDQN_online_20250915231326: epoch=10 step=100000\u001b[0m \u001b[36mepoch\u001b[0m=\u001b[35m10\u001b[0m \u001b[36mmetrics\u001b[0m=\u001b[35m{'time_inference': 7.761321067810058e-05, 'time_environment_step': 7.386636734008789e-06, 'time_sample_batch': 0.00024134397506713867, 'time_algorithm_update': 0.0006678747415542602, 'loss': 0.11973405434442684, 'time_step': 0.001004320478439331, 'rollout_return': 184.2962962962963}\u001b[0m \u001b[36mstep\u001b[0m=\u001b[35m100000\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100000/100000 [01:42<00:00, 976.50it/s]\n"
     ]
    }
   ],
   "source": [
    "import gymnasium as gym\n",
    "\n",
    "# setup experience replay buffer\n",
    "buffer = d3rlpy.dataset.create_fifo_replay_buffer(limit=100000, env=env)\n",
    "\n",
    "# setup exploration strategy if necessary\n",
    "explorer = d3rlpy.algos.ConstantEpsilonGreedy(0.1)\n",
    "\n",
    "# start finetuning\n",
    "dqn.fit_online(env, buffer, explorer, n_steps=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9542424",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cfd9158",
   "metadata": {},
   "source": [
    "## Finetune with Saved Policy\n",
    "\n",
    "If you want to finetune the saved policy, that’s also easy to do with d3rlpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549b40cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup algorithm\n",
    "dqn = d3rlpy.load_learnable(\"dqn_model.d3\")\n",
    "\n",
    "# start finetuning\n",
    "dqn.fit_online(env, buffer, explorer, n_steps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f53f815",
   "metadata": {},
   "source": [
    "## Finetune with Different Algorithm\n",
    "\n",
    "If you want to finetune the saved policy trained offline with online RL algorithms, you can do it in an out-of-the-box way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560c76f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup offline RL algorithm\n",
    "cql = d3rlpy.algos.DiscreteCQLConfig().create()\n",
    "\n",
    "# train offline\n",
    "cql.fit(dataset, n_steps=100000)\n",
    "\n",
    "# transfer to DQN\n",
    "dqn = d3rlpy.algos.DQNConfig().create()\n",
    "dqn.build_with_env(env)\n",
    "dqn.copy_q_function_from(cql)\n",
    "\n",
    "# start finetuning\n",
    "dqn.fit_online(env, buffer, explorer, n_steps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff34bc1",
   "metadata": {},
   "source": [
    "In actor-critic cases, you should also transfer the policy function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5dc388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# offline RL\n",
    "cql = d3rlpy.algos.CQLConfig().create()\n",
    "cql.fit(dataset, n_steps=100000)\n",
    "\n",
    "# transfer to SAC\n",
    "sac = d3rlpy.algos.SACConfig().create()\n",
    "sac.build_with_env(env)\n",
    "sac.copy_q_function_from(cql)\n",
    "sac.copy_policy_from(cql)\n",
    "\n",
    "# online RL\n",
    "sac.fit_online(env, buffer, n_steps=100000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python313",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
